{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.core.display import HTML\n",
    "# HTML(\"\"\"\n",
    "# <style>\n",
    "# .output_png {\n",
    "#     display: table-cell;\n",
    "#     text-align: center;\n",
    "#     vertical-align: middle;\n",
    "# }\n",
    "# </style>\n",
    "# \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Introduction Notebook\n",
    "\n",
    "In this notebook we'll revise a brief introduction into Natural Language Processing using Python.\n",
    "\n",
    "## Python libraries for NLP\n",
    "\n",
    "There exist a few main librarires to perform NLP, those are: Wordcloud, Spacy and NLTK, so we'll first install them in our environment in the following cell. Note that for spacy we dowload english language models, those will help us in analysing Part-Of-Speech, Named Entity Recognition, Lemmatizing, and more, which we'll explain further in this notebook.\n",
    "\n",
    "Note: If the following cell is still not installing the libraries in your environment, you can run them from the terminal (without the '!').\n",
    "\n",
    "You can read more about them in the following links:\n",
    "- Spacy: https://spacy.io/api/doc/\n",
    "- NLTK: https://www.nltk.org/\n",
    "- Wordcloud: https://amueller.github.io/word_cloud/\n",
    "- Yellowbrick: https://www.scikit-yb.org/en/latest/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important: if there's any trouble opening this notebook, use: 'conda install -c conda-forge jupyter_contrib_nbextensions '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Uncomment the following lines for installing the Spacy and NLTK libraries.\n",
    "# ! pip install pandas\n",
    "# ! pip install wordcloud\n",
    "# ! pip install nltk\n",
    "# ! pip install spacy\n",
    "# ! pip install pyldavis\n",
    "# ! pip install gensim\n",
    "# ! pip install yellowbrick\n",
    "# ! pip install vaderSentiment\n",
    "# ! python -m spacy download en_core_web_sm\n",
    "# ! python -m spacy download en_core_web_md\n",
    "# ! python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can import the libraries. We'll also be using pandas for data importation and manipulation, and matplotlib for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data wrangling and visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "from yellowbrick.text import FreqDistVisualizer\n",
    "\n",
    "# Text mining\n",
    "from gensim import models, corpora\n",
    "from gensim.models import LdaModel, CoherenceModel\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import pyLDAvis.gensim\n",
    "import spacy\n",
    "\n",
    "from nltk.cluster import KMeansClusterer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import re\n",
    "import time\n",
    "# nltk.download('punkt') # Uncomment this line if using for the first time the NLTK library\n",
    "# nltk.download('stopwords') # Uncomment this line if using for the first time the NLTK library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we'll be working with the following dataset, which contains information about reviews on Amazon products: https://www.kaggle.com/datafiniti/consumer-reviews-of-amazon-products.\n",
    "\n",
    "We will start by importing the '1429_1.csv' file which is the smallest of the three files downloaded from the Kaggle link above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Programs\\Anaconda\\envs\\thesis\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (1,10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/archive/1429_1.csv\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 34660 entries, 0 to 34659\n",
      "Data columns (total 21 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   id                    34660 non-null  object \n",
      " 1   name                  27900 non-null  object \n",
      " 2   asins                 34658 non-null  object \n",
      " 3   brand                 34660 non-null  object \n",
      " 4   categories            34660 non-null  object \n",
      " 5   keys                  34660 non-null  object \n",
      " 6   manufacturer          34660 non-null  object \n",
      " 7   reviews.date          34621 non-null  object \n",
      " 8   reviews.dateAdded     24039 non-null  object \n",
      " 9   reviews.dateSeen      34660 non-null  object \n",
      " 10  reviews.didPurchase   1 non-null      object \n",
      " 11  reviews.doRecommend   34066 non-null  object \n",
      " 12  reviews.id            1 non-null      float64\n",
      " 13  reviews.numHelpful    34131 non-null  float64\n",
      " 14  reviews.rating        34627 non-null  float64\n",
      " 15  reviews.sourceURLs    34660 non-null  object \n",
      " 16  reviews.text          34659 non-null  object \n",
      " 17  reviews.title         34655 non-null  object \n",
      " 18  reviews.userCity      0 non-null      float64\n",
      " 19  reviews.userProvince  0 non-null      float64\n",
      " 20  reviews.username      34658 non-null  object \n",
      "dtypes: float64(5), object(16)\n",
      "memory usage: 5.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that the amount of columns may serve for multiple types of analysis of sales on the Amazon products. For the sake of this notebook we'll focus in those that represent text information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"name\", \"brand\", \"categories\", \"manufacturer\", \"reviews.date\", \"reviews.rating\", \"reviews.text\", \"reviews.title\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset covers many products, we can see the most reviewed ones in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews.text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fire Tablet, 7 Display, Wi-Fi, 8 GB - Includes Special Offers, Magenta</th>\n",
       "      <td>10966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Echo (White),,,\\r\\nEcho (White),,,</th>\n",
       "      <td>3309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amazon Kindle Paperwhite - eBook reader - 4 GB - 6 monochrome Paperwhite - touchscreen - Wi-Fi - black,,,</th>\n",
       "      <td>3176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi, 16 GB - Includes Special Offers, Magenta</th>\n",
       "      <td>2814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amazon Fire Tv,,,\\r\\nAmazon Fire Tv,,,</th>\n",
       "      <td>2527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    reviews.text\n",
       "name                                                            \n",
       "Fire Tablet, 7 Display, Wi-Fi, 8 GB - Includes ...         10966\n",
       "Echo (White),,,\\r\\nEcho (White),,,                          3309\n",
       "Amazon Kindle Paperwhite - eBook reader - 4 GB ...          3176\n",
       "All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi, ...          2814\n",
       "Amazon Fire Tv,,,\\r\\nAmazon Fire Tv,,,                      2527"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"name\", \"reviews.text\"]].groupby([\"name\"]).count().sort_values([\"reviews.text\"], ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll focus on only the rating, text and title fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_most_reviews = df[df[\"name\"] == \"Fire Tablet, 7 Display, Wi-Fi, 8 GB - Includes Special Offers, Magenta\"]\n",
    "df = df[[\"reviews.rating\", \"reviews.text\", \"reviews.title\"]]\n",
    "df.columns = ['rating', 'text', 'title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping NA values in any of the text or title fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(axis=0, how='any', subset=['text', 'title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case of wanting to run the notebook faster, optionally we can grab a sample with a smaller amount of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(n=5000, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The count of reviews grouped by rating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"rating\", \"text\"]].groupby([\"rating\"]).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Distribution\n",
    "\n",
    "We can visualize the length of a set of texts, which first we need to get the count of words in each of the analyzed texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_title_count = []\n",
    "lista_text_count = []\n",
    "for index, row in df.iterrows():\n",
    "    title_count = 0\n",
    "    text_count = 0\n",
    "    title_count=len((str(row['title'])))\n",
    "    text_count=len((str(row['text'])))\n",
    "    lista_title_count.append(title_count)\n",
    "    lista_text_count.append(text_count)\n",
    "    \n",
    "df['title_count'] = lista_title_count\n",
    "df['text_count'] = lista_text_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving on into more specific analysis, first we will set every text to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"text\"].str.lower()\n",
    "df[\"title\"] = df[\"title\"].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next plot, we can visualize how an average of reviews are found to have from 10 to 30 words in the title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(12,8)})\n",
    "sns.displot(df, x=\"title_count\", col=\"rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(12,8)})\n",
    "sns.displot(df[df['rating']==5.0], x=\"title_count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next plot, we can visualize the distribution for the body texts on the reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(df, x=\"text_count\", col=\"rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(df[df['rating']==5.0], x=\"text_count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the plot above we can observe that there are some reviews that are too long, we can prove that there exist these outlier reviews by plotting a box plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=\"rating\", y=\"text_count\", data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['text_count'] > 5000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wordclouds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A wordcloud may give insight into which words are mentioned the most in a set of texts, as shown in the following example wordcloud:\n",
    "<p></p>\n",
    "<div>\n",
    "<img src=\"wordcloud_example.jpg\" width=\"500\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the titles of each review we can obtain the wordcloud as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse all the rows into a single string\n",
    "title_text = \" \".join(text for text in df[\"title\"])\n",
    "print (\"Hay {} palabras en titulos.\".format(len(title_text)))\n",
    "\n",
    "# Generate a word cloud image:\n",
    "wordcloud = WordCloud().generate(title_text)\n",
    "\n",
    "# Display the generated image:\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"WordCloud Titles\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More specifically, we could observe what the wordcloud would be like for each of the ratings in the reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = 1.0\n",
    "# Parse all the rows into a single string\n",
    "title_text = \" \".join(text for text in df[df[\"rating\"] == rating][\"title\"])\n",
    "print (\"Hay {} palabras en titulos.\".format(len(title_text)))\n",
    "\n",
    "# Generate a word cloud image:\n",
    "wordcloud = WordCloud().generate(title_text)\n",
    "\n",
    "# Display the generated image:\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"WordCloud Titles\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the same process, we can apply the same function to the reviews body texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse all the rows into a single string\n",
    "body_text = \" \".join(text for text in df[\"text\"])\n",
    "print (\"Hay {} palabras en textos.\".format(len(body_text)))\n",
    "\n",
    "# Generate a word cloud image:\n",
    "wordcloud = WordCloud().generate(body_text)\n",
    "\n",
    "# Display the generated image:\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"WordCloud texts\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can perform the same rating-specific approach as with the titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = 5.0\n",
    "# Parse all the rows into a single string\n",
    "body_text = \" \".join(text for text in df[df[\"rating\"] == rating][\"text\"])\n",
    "print (\"Hay {} palabras en textos.\".format(len(body_text)))\n",
    "\n",
    "# Generate a word cloud image:\n",
    "wordcloud = WordCloud().generate(body_text)\n",
    "\n",
    "# Display the generated image:\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"WordCloud texts\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most frequent words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will introduce a couple of useful functions. \n",
    "\n",
    "We will being by assigning the stopwords information into the sw variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using NLTK FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = 5.0\n",
    "if rating == None:\n",
    "    words = \" \".join(text for text in df[\"title\"])\n",
    "else:\n",
    "    words = \" \".join(text for text in df[df[\"rating\"] == rating][\"title\"])\n",
    "words = nltk.word_tokenize(words)\n",
    "words = [word for word in words if word not in sw and re.match('([a-zA-Z0-9]+)',word)]\n",
    "freqdist = nltk.FreqDist(words)\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.title(\"Frecuencia de palabras en Title\")\n",
    "freqdist.plot(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Yellowbricks FreqDistVisualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the text data\n",
    "rating = 1.0\n",
    "if rating == None:\n",
    "    corpus = df[\"title\"]\n",
    "else:\n",
    "    corpus = df[df[\"rating\"] == rating][\"title\"]\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "docs       = vectorizer.fit_transform(text for text in corpus)\n",
    "features   = vectorizer.get_feature_names()\n",
    "\n",
    "visualizer = FreqDistVisualizer(\n",
    "    features=features, size=(1080, 720)\n",
    ")\n",
    "visualizer.fit(docs)\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the text in the reviews\n",
    "\n",
    "Using NLTK FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = 5.0\n",
    "if rating == None:\n",
    "    words = \" \".join(text for text in df[\"text\"])\n",
    "else:\n",
    "    words = \" \".join(text for text in df[df[\"rating\"] == rating][\"text\"])\n",
    "words = nltk.word_tokenize(words)\n",
    "words = [word for word in words if word not in sw and re.match('([a-zA-Z0-9]+)',word)]\n",
    "freqdist = nltk.FreqDist(words)\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.title(\"Frecuencia de palabras en Text\")\n",
    "freqdist.plot(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Yellowbrick FreqDistVisualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the text data\n",
    "rating = 5.0\n",
    "if rating == None:\n",
    "    corpus = df[\"text\"]\n",
    "else:\n",
    "    corpus = df[df[\"rating\"] == rating][\"text\"]\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "docs       = vectorizer.fit_transform(text for text in corpus)\n",
    "features   = vectorizer.get_feature_names()\n",
    "\n",
    "visualizer = FreqDistVisualizer(\n",
    "    features=features, size=(1080, 720)\n",
    ")\n",
    "visualizer.fit(docs)\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis\n",
    "\n",
    "Ratings of 1.0, 2.0, 3.0 may be considered bad.\n",
    "Ratings of 4.0, 5.0 may be considered good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by initializing the sentiment analyzer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyser = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analyzer_scores(sentence, show = False):\n",
    "    score = analyser.polarity_scores(sentence)\n",
    "    if show:\n",
    "        print(\"{:-<40} {}\".format(sentence, str(score)))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = sentiment_analyzer_scores(\"I think the movie was incredibly bad!!:(\", True)\n",
    "type(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_sentiment_neg = []\n",
    "lista_sentiment_neu = []\n",
    "lista_sentiment_pos = []\n",
    "lista_sentiment_comp = []\n",
    "\n",
    "for index, row in enumerate(df.itertuples(), 1):\n",
    "    sentiment = sentiment_analyzer_scores(row.text)\n",
    "    lista_sentiment_neg.append(sentiment['neg'])\n",
    "    lista_sentiment_neu.append(sentiment['neu'])\n",
    "    lista_sentiment_pos.append(sentiment['pos'])\n",
    "    lista_sentiment_comp.append(sentiment['compound'])\n",
    "\n",
    "df['sentiment_neg'] = lista_sentiment_neg\n",
    "df['sentiment_neu'] = lista_sentiment_neu\n",
    "df['sentiment_pos'] = lista_sentiment_pos\n",
    "df['sentiment_comp'] = lista_sentiment_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df, x='rating', y='sentiment_comp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization is the process of demarcating and possibly classifying sections of a string of input characters. The resulting tokens are then passed on to some other form of processing. The process can be considered a sub-task of parsing input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_text = \"The incredible tale of a man who formed an unlikely bond with an octopus ! ?\"\n",
    "tokens = nltk.word_tokenize(example_text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_tokens = []\n",
    "\n",
    "for index, row in enumerate(df.itertuples(), 1):\n",
    "    sentence = row.text\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    lista_tokens.append(tokens)\n",
    "    \n",
    "df['tokens_text'] = lista_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens_text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Cleaning\n",
    "\n",
    "Stemming and lemmatization are used to clean a dataset by either cutting the words into a root form (stem), or by replacing them to their equivalent word that would be found in a dictionary (lemma).\n",
    "\n",
    "Normalizing format is important when dealing with alphabetical texts. There exist more techniques that allow for the cleaning to respect e.g. emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.strip()\n",
    "df['text'] = df['text'].str.strip()\n",
    "df['text'] = df['text'].str.lower()\n",
    "df['text'] = df['text'].str.normalize('NFKD')\\\n",
    "       .str.encode('ascii', errors='ignore')\\\n",
    "       .str.decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(language='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_text_stem = []\n",
    "\n",
    "for index, row in enumerate(df.itertuples(), 1):\n",
    "    tokens = row.tokens_text\n",
    "    stems = []\n",
    "    for token in tokens:\n",
    "        stem = stemmer.stem(token)\n",
    "        if len(stem) > 0:\n",
    "            stems.append(stem)\n",
    "    text_stem = \" \".join(text for text in stems)\n",
    "    lista_text_stem.append(text_stem)\n",
    "    \n",
    "df['text_stem'] = lista_text_stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_stem'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_text = \"The red fox jumps through the wall and hides beneath the tree.\"\n",
    "\n",
    "for token in nlp(demo_text):\n",
    "    print(f\"{'token: ' + str(token):<15} - {'lemma: ' + token.lemma_:<15} - {'pos: ' + token.pos_:<10} - {'ent: ' + token.ent_type_:<10}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_text = \"Michael Jordan talked with Nike about a new deal worth $1B USD! #money #basketball\"\n",
    "\n",
    "for token in nlp(demo_text):\n",
    "    print(f\"{'token: ' + str(token):<15} - {'lemma: ' + token.lemma_:<15} - {'pos: ' + token.pos_:<10} - {'ent: ' + token.ent_type_:<10}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_text_lemma = []\n",
    "\n",
    "for sentence in list(nlp.pipe(df['text'], disable=['ner', 'parser'])):\n",
    "    lemmas = []\n",
    "    for token in sentence:\n",
    "        lemma = str(token.lemma_)\n",
    "        if (len(lemma) > 0) and (lemma != '-PRON-') and (lemma not in sw) and (re.match('([a-zA-Z]+)',token.text) != None):\n",
    "            lemmas.append(lemma)\n",
    "    text_lemma= \" \".join(text for text in lemmas)\n",
    "    lista_text_lemma.append(text_lemma)\n",
    "    \n",
    "df['text_lemma'] = lista_text_lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_lemma'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../data/results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling\n",
    "\n",
    "What are the main topics of the reviews?\n",
    "Quick LDA and pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = []\n",
    "def train_lda(data, num_topics=10):\n",
    "    \"\"\"\n",
    "    This function trains the lda model\n",
    "    We setup parameters like number of topics, the chunksize to use in Hoffman method\n",
    "    We also do 2 passes of the data since this is a small dataset, so we want the distributions to stabilize\n",
    "    \"\"\"\n",
    "    chunksize = 300\n",
    "    t1 = time.time()\n",
    "    for doc in list(nlp.pipe(df['text_lemma'], disable=['ner', 'parser'])):\n",
    "        tokens = []\n",
    "        for token in doc:\n",
    "            tokens.append(token.text)\n",
    "        tokenized.append(tokens)\n",
    "    dictionary = corpora.Dictionary(tokenized)\n",
    "    corpus = [dictionary.doc2bow(doc) for doc in tokenized]\n",
    "    # low alpha means each document is only represented by a small number of topics, and vice versa\n",
    "    # low eta means each topic is only represented by a small number of words, and vice versa\n",
    "    lda = LdaModel(corpus=corpus, num_topics=num_topics, id2word=dictionary,\n",
    "                   alpha=1e-2, eta=0.5e-2, chunksize=chunksize, minimum_probability=0.0, passes=2)\n",
    "    t2 = time.time()\n",
    "    print(\"Time to train LDA model on \", len(df), \"articles: \", (t2-t1)/60, \"min\")\n",
    "    return dictionary,corpus,lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary,corpus,lda = train_lda(df, num_topics=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda, texts=tokenized, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda, texts=tokenized, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = dictionary.doc2bow(text.split())\n",
    "t = lda.get_document_topics(bow)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_topics = []\n",
    "list_topic_scores = []\n",
    "for index, row in enumerate(df.itertuples(), 1):\n",
    "    text = row.text\n",
    "    bow = dictionary.doc2bow(text.split())\n",
    "    t = lda.get_document_topics(bow)\n",
    "    topic = sorted(t, key=lambda x: x[1], reverse=True)[0][0]\n",
    "    topic_score = sorted(t, key=lambda x: x[1], reverse=True)[0][1]\n",
    "    list_topics.append(topic)\n",
    "    list_topic_scores.append(topic_score)\n",
    "df['topicLDA'] = list_topics\n",
    "df['topicLDA_score'] = list_topic_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../data/results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda, corpus, dictionary)\n",
    "vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "\n",
    "K-Means with silhouette score and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.text_lemma = df.text_lemma.fillna(' ')\n",
    "encode = CountVectorizer(binary=True)\n",
    "freqs = encode.fit_transform(df['text_lemma'])\n",
    "vect = [freq.toarray()[0] for freq in freqs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KMeansClusterer(5, nltk.cluster.util.euclidean_distance, avoid_empty_clusters = True,rng=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = model.cluster(vect, True, trace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Clustered:\", vect)\n",
    "print(\"As:\", clusters)\n",
    "print(\"Means:\", model.means())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clusters_eucliean'] = clusters \n",
    "df.to_csv(\"../data/results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from yellowbrick.cluster import SilhouetteVisualizer\n",
    "import numpy\n",
    "\n",
    "bow = CountVectorizer()\n",
    "X_bow = bow.fit_transform(df.text_lemma)\n",
    "        \n",
    "visualizer = SilhouetteVisualizer(KMeans(n_clusters=5, random_state=0))\n",
    "visualizer.fit(X_bow)\n",
    "visualizer.poof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "\n",
    "visualizer = KElbowVisualizer(KMeans(random_state=0), metric='silhouette', k=range(3, 21, 1))\n",
    "visualizer.fit(X_bow)\n",
    "visualizer.poof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from yellowbrick.text import TSNEVisualizer\n",
    "\n",
    "# Load the data and create document vectors\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "X = tfidf.fit_transform(df.text)\n",
    "y = df.clusters_nltk_cos\n",
    "\n",
    "# Create the visualizer and draw the vectors\n",
    "tsne = TSNEVisualizer()\n",
    "tsne.fit(X, y)\n",
    "tsne.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
